# Ollama Shim Service Environment Variables
#
# Create a .env file in this directory for actual configuration.
# All variables are optional as they have defaults defined in code.

# LM Studio connection settings
LM_STUDIO_BASE_URL=http://localhost:1234
AUTH_TOKEN=  # Add your authentication token if required

# Network timeouts
API_TIMEOUT=30.0      # Timeout (in seconds) for the OpenAI API request
RESPONSE_TIMEOUT=300.0  # Max wait time for a response from the model
SHIM_PORT=11434     # Port for the Ollama Shim service to listen on