# Ollama Shim Service Environment Variables
#
# Create a .env file in this directory for actual configuration.
# All variables are optional as they have defaults defined in code.

# LM Studio connection settings (change if not using default port/host)
LM_STUDIO_URL=http://localhost:1234
AUTH_TOKEN=  # Add your authentication token if required (e.g., sk-YOUR_KEY)

# Network timeouts
API_TIMEOUT=5.0      # Timeout (in seconds) for the OpenAI API request
RESPONSE_TIMEOUT=300.0  # Max wait time for a response from the model

# Ollama Shim service settings
SHIM_PORT=11435     # Port for the Ollama Shim service to listen on
LOG_LEVEL=INFO      # Logging level for console (DEBUG, INFO, WARNING, ERROR, CRITICAL)
FILE_LOG_LEVEL=DEBUG # Logging level for file (DEBUG, INFO, WARNING, ERROR, CRITICAL)
